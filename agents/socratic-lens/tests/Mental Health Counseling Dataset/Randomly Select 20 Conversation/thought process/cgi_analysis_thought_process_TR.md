# CGI Analiz SÃ¼reci: Kod ve DÃ¼ÅŸÃ¼nce AdÄ±mlarÄ±

## ğŸ“‹ Ä°Ã§indekiler
1. [Problem ve YaklaÅŸÄ±m](#problem-ve-yaklaÅŸÄ±m)
2. [AdÄ±m 1: Parquet DosyasÄ± Okuma Denemeleri](#adÄ±m-1-parquet-dosyasÄ±-okuma-denemeleri)
3. [AdÄ±m 2: Manuel Metin Ã‡Ä±karma](#adÄ±m-2-manuel-metin-Ã§Ä±karma)
4. [AdÄ±m 3: Temiz Veri Ã‡Ä±karma](#adÄ±m-3-temiz-veri-Ã§Ä±karma)
5. [AdÄ±m 4: CGI Lens OluÅŸturma ve Analiz](#adÄ±m-4-cgi-lens-oluÅŸturma-ve-analiz)
6. [AdÄ±m 5: Final Rapor Ãœretimi](#adÄ±m-5-final-rapor-Ã¼retimi)
7. [SonuÃ§lar](#sonuÃ§lar)

---

## Problem ve YaklaÅŸÄ±m

### KarÅŸÄ±laÅŸÄ±lan Sorun
- Parquet dosyasÄ±nÄ± okumak iÃ§in `pyarrow` veya `fastparquet` kÃ¼tÃ¼phaneleri gerekli
- AÄŸ eriÅŸimi kapalÄ± olduÄŸu iÃ§in pip ile kurulum yapÄ±lamadÄ±
- **Ã‡Ã¶zÃ¼m:** Parquet dosyasÄ±ndan doÄŸrudan binary okuma ile metin Ã§Ä±karma

### DÃ¼ÅŸÃ¼nce SÃ¼reci
```
1. pyarrow yÃ¼kleme denemesi â†’ BaÅŸarÄ±sÄ±z (aÄŸ yok)
2. Mevcut kÃ¼tÃ¼phaneleri kontrol â†’ pandas var, pyarrow yok
3. Alternatif: Raw binary okuma ile metin Ã§Ä±karma
4. Parquet yapÄ±sÄ±nÄ± anlama â†’ PAR1 magic bytes, footer metadata
5. String pattern matching ile konuÅŸma metinlerini bulma
```

---

## AdÄ±m 1: Parquet DosyasÄ± Okuma Denemeleri

### Kod 1.1: KÃ¼tÃ¼phane Kurulum Denemesi
```python
# BaÅŸarÄ±sÄ±z - aÄŸ eriÅŸimi yok
pip install pandas pyarrow --break-system-packages -q
```

### Kod 1.2: Mevcut KÃ¼tÃ¼phaneleri Kontrol
```python
python3 -c "import pandas; print('pandas version:', pandas.__version__)"
# Ã‡Ä±ktÄ±: pandas version: 2.3.3

python3 -c "import pyarrow; print(pyarrow.__version__)" 
# Hata: ModuleNotFoundError: No module named 'pyarrow'
```

### DÃ¼ÅŸÃ¼nce
> "pyarrow yok, ama parquet dosyasÄ± binary formatÄ±nda. 
> Parquet'in yapÄ±sÄ±nÄ± anlarsam, metinleri doÄŸrudan Ã§Ä±karabilirim."

---

## AdÄ±m 2: Manuel Metin Ã‡Ä±karma

### Kod 2.1: Dosya YapÄ±sÄ±nÄ± Anlama
```python
"""
Parquet dosya yapÄ±sÄ±nÄ± inceleme
"""
import struct

filepath = "/mnt/user-data/uploads/0000.parquet"

with open(filepath, 'rb') as f:
    data = f.read()

# Parquet format:
# - "PAR1" ile baÅŸlar
# - "PAR1" ile biter
# - Footer metadata sonda

footer_length = struct.unpack('<I', data[-8:-4])[0]
print(f"Footer length: {footer_length}")

# "Context" ve "Response" sÃ¼tun isimlerini ara
for i in range(len(data) - 10):
    if data[i:i+7] == b'Context':
        print(f"Found 'Context' at position: {i}")
    if data[i:i+8] == b'Response':
        print(f"Found 'Response' at position: {i}")
```

### Kod 2.2: Ä°lk Metin Ã‡Ä±karma Denemesi
```python
"""
strings komutu benzeri - okunabilir metinleri Ã§Ä±kar
"""
head -c 10000 /mnt/user-data/uploads/0000.parquet | strings | head -200
```

### DÃ¼ÅŸÃ¼nce
> "Dosyada 'Context' ve 'Response' sÃ¼tun isimleri var.
> Veriler sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ ama bazÄ± metinler doÄŸrudan okunabilir.
> Daha sofistike bir yaklaÅŸÄ±m gerekiyor."

---

## AdÄ±m 3: Temiz Veri Ã‡Ä±karma

### Kod 3.1: AkÄ±llÄ± Metin Ã‡Ä±karÄ±cÄ±
```python
"""
Parquet dosyasÄ±ndan temiz konuÅŸma metinlerini Ã§Ä±kar
Binary verideki ASCII dizilerini bulur
"""
import re

filepath = "/mnt/user-data/uploads/0000.parquet"

with open(filepath, 'rb') as f:
    data = f.read()

def extract_clean_texts(data, min_len=60, max_len=3000):
    """
    Binary veriden temiz metin dizileri Ã§Ä±kar
    
    MantÄ±k:
    - Her byte'Ä± kontrol et
    - YazdÄ±rÄ±labilir ASCII (32-126) veya newline ise ekle
    - UTF-8 lead byte'larÄ± iÃ§in Ã¶zel iÅŸlem
    - Yeterli uzunlukta ve kalitede ise kaydet
    """
    texts = []
    current = []
    
    for i, byte in enumerate(data):
        # YazdÄ±rÄ±labilir ASCII veya whitespace
        if 32 <= byte <= 126 or byte in [10, 13, 9]:
            current.append(chr(byte))
        # UTF-8 lead bytes (Ã©, Ã¶ gibi karakterler iÃ§in)
        elif byte in [195, 196, 197]:
            if i + 1 < len(data):
                next_byte = data[i + 1]
                if 128 <= next_byte <= 191:
                    try:
                        char = bytes([byte, next_byte]).decode('utf-8')
                        current.append(char)
                        continue
                    except:
                        pass
            current.append(' ')
        else:
            # Binary karakter - mevcut diziyi deÄŸerlendir
            if len(current) >= min_len:
                text = ''.join(current).strip()
                # Kalite kontrolÃ¼
                alpha_ratio = sum(c.isalpha() for c in text) / max(len(text), 1)
                if alpha_ratio > 0.5 and len(text) >= min_len and len(text) <= max_len:
                    # Kelime boÅŸluklarÄ± var mÄ±?
                    if text.count(' ') > 5:
                        texts.append(text)
            current = []
    
    return texts

texts = extract_clean_texts(data, min_len=80)
print(f"Found {len(texts)} clean text blocks")
```

### Kod 3.2: KullanÄ±cÄ±/DanÄ±ÅŸman AyrÄ±mÄ±
```python
"""
Metinleri Context (kullanÄ±cÄ±) ve Response (danÄ±ÅŸman) olarak sÄ±nÄ±fla
"""
# KullanÄ±cÄ± mesajÄ± kalÄ±plarÄ±
user_patterns = [
    r"^I[\'']m\s",      # "I'm feeling..."
    r"^I\s",            # "I have..."
    r"^My\s",           # "My husband..."
    r"^We\s",           # "We have been..."
    r"\?$",             # Soru ile biter
    r"I feel",
    r"I don\'t know",
    r"struggling|going through|worried|anxious|depressed"
]

# DanÄ±ÅŸman mesajÄ± kalÄ±plarÄ±
counselor_patterns = [
    r"^It sounds like",
    r"^Thank you for",
    r"^I hear",
    r"^That sounds",
    r"therapist|counselor|therapy|treatment",
    r"suggest|recommend|encourage",
    r"practice|skill|technique"
]

contexts = []  # KullanÄ±cÄ± mesajlarÄ±
responses = [] # DanÄ±ÅŸman mesajlarÄ±

for text in texts:
    is_user = any(re.search(pat, text, re.IGNORECASE) for pat in user_patterns)
    is_counselor = any(re.search(pat, text, re.IGNORECASE) for pat in counselor_patterns)
    
    if is_counselor and len(text) > 100:
        responses.append(text)
    elif is_user and not is_counselor:
        contexts.append(text)

print(f"Contexts: {len(contexts)}, Responses: {len(responses)}")
```

### DÃ¼ÅŸÃ¼nce
> "178 temiz metin bloÄŸu bulundu.
> BunlarÄ±n 15'i kullanÄ±cÄ± mesajÄ±, 33'Ã¼ danÄ±ÅŸman yanÄ±tÄ±.
> CGI analizi iÃ§in danÄ±ÅŸman yanÄ±tlarÄ±nÄ± kullanacaÄŸÄ±m."

---

## AdÄ±m 4: CGI Lens OluÅŸturma ve Analiz

### Kod 4.1: CGI Lens TanÄ±mÄ±
```python
"""
CGI (Context Grammar Induction) Lens
Mental saÄŸlÄ±k danÄ±ÅŸmanlÄ±ÄŸÄ± iÃ§in Ã¶zelleÅŸtirilmiÅŸ
"""

CGI_LENS = {
    "corpus_character": "Mental health counseling conversations",
    
    "context_grammar": {
        "description": "KullanÄ±cÄ±nÄ±n problemi anlama Ã§erÃ§evesi",
        "axes": [
            "SELF-CONCEPT: Kim olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yor",
            "ONTOLOGY: Neyin gerÃ§ek/mÃ¼mkÃ¼n olduÄŸuna inanÄ±yor",
            "ATTRIBUTION: Neyi/kimi suÃ§luyor"
        ]
    },
    
    "decision_question": """
        Bu yanÄ±t kullanÄ±cÄ±nÄ±n TEMEL Ã‡ERÃ‡EVESÄ°NÄ° deÄŸiÅŸtiriyor mu
        (kendini, problemini, mÃ¼mkÃ¼n olanÄ± nasÄ±l gÃ¶rdÃ¼ÄŸÃ¼)
        yoksa sadece o Ã§erÃ§eve Ä°Ã‡Ä°NDE doÄŸruluyor/optimize mi ediyor?
    """,
    
    "transformative_signals": [
        "KullanÄ±cÄ±nÄ±n kimlik tanÄ±mÄ±nÄ± sorgular",
        "Problem ontolojisini yeniden Ã§erÃ§eveler",
        "Ã–rtÃ¼k varsayÄ±mlarÄ± sorgular",
        "Yeni olasÄ±lÄ±k alanÄ± aÃ§ar"
    ],
    
    "mechanical_signals": [
        "DuygularÄ± kaynaÄŸÄ±nÄ± sorgulamadan doÄŸrular",
        "Semptom yÃ¶netimi teknikleri Ã¶nerir",
        "Profesyonel yardÄ±ma yÃ¶nlendirir",
        "Mevcut dÃ¼nya gÃ¶rÃ¼ÅŸÃ¼ iÃ§inde davranÄ±ÅŸ tavsiyesi verir",
        "Deneyimi normalleÅŸtirir"
    ]
}
```

### Kod 4.2: Analiz Fonksiyonu
```python
"""
Her yanÄ±tÄ± CGI lens'e gÃ¶re analiz et
"""
def analyze_response(response):
    """
    Bir danÄ±ÅŸman yanÄ±tÄ±nÄ± TRANSFORMATIVE veya MECHANICAL olarak sÄ±nÄ±fla
    """
    transformative_signals = []
    mechanical_signals = []
    
    # === TRANSFORMATIVE SÄ°NYALLERÄ° KONTROL ET ===
    
    # Yeniden Ã§erÃ§eveleme daveti
    if re.search(r'(what if|imagine|consider that|reframe|perspective)', response, re.I):
        transformative_signals.append("Invites reframing")
    
    # Kimlik sorgulamasÄ±
    if re.search(r'(who you are|your identity|you are not|rooted in|underlying)', response, re.I):
        transformative_signals.append("Challenges self-definition/root cause")
    
    # Altta yatan konuya iÅŸaret
    if re.search(r'(the real question|beneath|deeper|root|actually about)', response, re.I):
        transformative_signals.append("Points to underlying issue")
    
    # Ontoloji deÄŸiÅŸikliÄŸi
    if re.search(r'(isn\'t about|not really about|what it means to)', response, re.I):
        transformative_signals.append("Reframes problem ontology")
    
    # === MECHANICAL SÄ°NYALLERÄ° KONTROL ET ===
    
    # DoÄŸrulama/yansÄ±tma
    if re.search(r'(it sounds like you|I hear that|I understand|that must be)', response, re.I):
        mechanical_signals.append("Validation/reflection")
    
    # Teknik Ã¶nerisi
    if re.search(r'(try|technique|skill|practice|exercise|breathing)', response, re.I):
        mechanical_signals.append("Technique recommendation")
    
    # Profesyonel yÃ¶nlendirme
    if re.search(r'(therapist|counselor|professional|doctor|seek help)', response, re.I):
        mechanical_signals.append("Professional referral")
    
    # DavranÄ±ÅŸ tavsiyesi
    if re.search(r'(should|need to|have to|consider doing|suggest)', response, re.I):
        mechanical_signals.append("Behavioral advice")
    
    # NormalleÅŸtirme
    if re.search(r'(normal|common|many people|not alone)', response, re.I):
        mechanical_signals.append("Normalization")
    
    # === KARAR VER ===
    t_score = len(transformative_signals)
    m_score = len(mechanical_signals)
    
    if t_score >= 2 and t_score > m_score:
        verdict = 'TRANSFORMATIVE'
        confidence = 'high' if t_score >= 3 else 'medium'
    elif m_score >= 1:
        verdict = 'MECHANICAL'
        confidence = 'high' if m_score >= 3 else 'medium' if m_score >= 2 else 'low'
    else:
        verdict = 'MECHANICAL'
        confidence = 'low'
    
    return {
        'verdict': verdict,
        'confidence': confidence,
        'transformative_signals': transformative_signals,
        'mechanical_signals': mechanical_signals
    }
```

### Kod 4.3: 20 Ã–rnek Ãœzerinde Analiz
```python
"""
20 rastgele danÄ±ÅŸman yanÄ±tÄ±nÄ± analiz et
"""
import random

random.seed(42)  # Tekrarlanabilirlik iÃ§in

# 20 Ã¶rnek seÃ§
sample_responses = random.sample(responses, min(20, len(responses)))

# Her birini analiz et
results = []
for idx, response in enumerate(sample_responses, 1):
    analysis = analyze_response(response)
    results.append({
        'id': idx,
        'text': response[:500],
        **analysis
    })

# SonuÃ§larÄ± Ã¶zetle
verdicts = {'TRANSFORMATIVE': 0, 'MECHANICAL': 0}
for r in results:
    verdicts[r['verdict']] += 1

print(f"TRANSFORMATIVE: {verdicts['TRANSFORMATIVE']}")
print(f"MECHANICAL: {verdicts['MECHANICAL']}")
```

### DÃ¼ÅŸÃ¼nce
> "Karar sorusu kritik: 'Bu yanÄ±t Ã§erÃ§eveyi DEÄÄ°ÅTÄ°RÄ°YOR mu yoksa 
> Ã§erÃ§eve Ä°Ã‡Ä°NDE mi Ã§alÄ±ÅŸÄ±yor?'
> 
> Ã‡oÄŸu danÄ±ÅŸman yanÄ±tÄ± mekanik Ã§Ä±kÄ±yor Ã§Ã¼nkÃ¼:
> - DuygularÄ± doÄŸruluyorlar (validation)
> - Teknikler Ã¶neriyorlar (coping)
> - Terapiste yÃ¶nlendiriyorlar (deferral)
> 
> Bunlar deÄŸerli ama dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ deÄŸil."

---

## AdÄ±m 5: Final Rapor Ãœretimi

### Kod 5.1: Markdown Rapor Ãœretici
```python
"""
CGI Analiz Raporu Ãœretici
"""
report = []

# BaÅŸlÄ±k
report.append("# CGI Analysis Report: Mental Health Counseling Dataset")
report.append("")

# Lens konfigÃ¼rasyonu
report.append("## Lens Configuration")
report.append("")
report.append("**Decision Question:** Does the counselor's response shift the user's "
              "underlying frame (Ontology/Belief) or just validate/optimize it?")
report.append("")

# SonuÃ§ tablosu
report.append("| # | Verdict | Confidence | Key Signals | Response Preview |")
report.append("|---|---------|------------|-------------|------------------|")

for r in results:
    preview = r['text'][:80].replace('\n', ' ') + "..."
    signals = ', '.join(r['mechanical_signals'][:2]) if r['mechanical_signals'] else "N/A"
    report.append(f"| {r['id']:02d} | **{r['verdict']}** | {r['confidence']} | {signals} | {preview} |")

# Sokratik yansÄ±ma
report.append("")
report.append("## Socratic Meta-Reflection")
report.append("")
report.append("Mental health counseling responses predominantly operate in **MECHANICAL mode**.")
report.append("They help users cope within their existing frame rather than transforming it.")

# Kaydet
with open("/mnt/user-data/outputs/cgi_analysis_report.md", 'w') as f:
    f.write('\n'.join(report))
```

---

## SonuÃ§lar

### Final Ä°statistikler
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Verdict             â”‚ Count â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TRANSFORMATIVE      â”‚ 0     â”‚
â”‚ MECHANICAL          â”‚ 20    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Mekanik YanÄ±t KalÄ±plarÄ± (Bulunan)
| KalÄ±p | SayÄ± |
|-------|------|
| Professional referral | 12 |
| Technique recommendation | 9 |
| Behavioral advice | 7 |
| Validation/reflection | 2 |
| Normalization | 2 |

### Anahtar Bulgular

1. **HiÃ§bir dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ yanÄ±t bulunamadÄ±** - TÃ¼m 20 Ã¶rnek mekanik

2. **En yaygÄ±n kalÄ±p:** "Bir terapiste gÃ¶rÃ¼nÃ¼n" (professional referral)

3. **Eksik olan:**
   - Ä°Ã§ eleÅŸtirmeni sorgulama ("O ses kimin?")
   - Kimlik tanÄ±mÄ±nÄ± deÄŸiÅŸtirme ("Sen 'depresif' deÄŸilsin")
   - Ontolojik yeniden Ã§erÃ§eveleme ("Bu aslÄ±nda X ile ilgili deÄŸil")

### Transformatif YanÄ±t Ã–rneÄŸi (Veri setinde YOK)

Mekanik:
> "Zor bir dÃ¶nemden geÃ§iyorsunuz gibi gÃ¶rÃ¼nÃ¼yor. Bir terapist gÃ¶rmenizi Ã¶neririm."

Transformatif:
> "'DeÄŸersiz' olduÄŸunuzu sÃ¶ylÃ¼yorsunuz - ama kimin iÃ§in deÄŸersiz? O yargÄ±Ã§ kim? 
> Ya o yargÄ±Ã§ yanÄ±lÄ±yorsa?"

---

## KullanÄ±lan AraÃ§lar ve Teknikler

| AraÃ§ | KullanÄ±m |
|------|----------|
| Binary file parsing | Parquet yapÄ±sÄ±nÄ± anlama |
| Regex pattern matching | Metin sÄ±nÄ±flandÄ±rma |
| Statistical sampling | 20 Ã¶rnek seÃ§imi |
| CGI framework | DÃ¶nÃ¼ÅŸÃ¼m analizi |

---

## Dosya YapÄ±sÄ±

```
/home/claude/
â”œâ”€â”€ read_parquet.py          # Ä°lk okuma denemesi
â”œâ”€â”€ extract_parquet.py       # YapÄ± analizi
â”œâ”€â”€ better_extract.py        # Ä°yileÅŸtirilmiÅŸ Ã§Ä±karÄ±cÄ±
â”œâ”€â”€ parquet_manual.py        # Manuel parser
â”œâ”€â”€ parquet_decode.py        # Pattern matching
â”œâ”€â”€ extract_clean.py         # Temiz metin Ã§Ä±karÄ±cÄ±
â”œâ”€â”€ cgi_analysis.py          # CGI analiz engine
â””â”€â”€ cgi_final_report.py      # Rapor Ã¼retici

/mnt/user-data/outputs/
â””â”€â”€ cgi_analysis_report.md   # Final rapor
```

#!/usr/bin/env python3
"""
CGI (Context Grammar Induction) Analiz Scripti
==============================================

Mental saÄŸlÄ±k danÄ±ÅŸmanlÄ±ÄŸÄ± veri seti Ã¼zerinde Sokratik Lens analizi yapar. -https://huggingface.co/datasets/Amod/mental_health_counseling_conversations

KullanÄ±m:
    python cgi_complete_script.py /path/to/0000.parquet

Ã‡Ä±ktÄ±:
    - Konsola analiz sonuÃ§larÄ±
    - cgi_report.md dosyasÄ±

Yazar: Claude (Anthropic)
Tarih: 2025
"""

import re
import random
import struct
import sys
from pathlib import Path


# =============================================================================
# BÃ–LÃœM 1: PARQUET VERÄ° Ã‡IKARICI
# =============================================================================

def extract_clean_texts(data: bytes, min_len: int = 60, max_len: int = 3000) -> list[str]:
    """
    Binary parquet verisinden temiz metin dizileri Ã§Ä±karÄ±r.
    
    Parquet kÃ¼tÃ¼phanesi olmadan Ã§alÄ±ÅŸÄ±r - doÄŸrudan byte analizi yapar.
    
    Args:
        data: Ham binary veri
        min_len: Minimum metin uzunluÄŸu
        max_len: Maksimum metin uzunluÄŸu
    
    Returns:
        Temiz metin listesi
    """
    texts = []
    current = []
    
    for i, byte in enumerate(data):
        # YazdÄ±rÄ±labilir ASCII veya whitespace
        if 32 <= byte <= 126 or byte in [10, 13, 9]:
            current.append(chr(byte))
        # UTF-8 lead bytes (TÃ¼rkÃ§e/Ã¶zel karakterler iÃ§in)
        elif byte in [195, 196, 197]:
            if i + 1 < len(data):
                next_byte = data[i + 1]
                if 128 <= next_byte <= 191:
                    try:
                        char = bytes([byte, next_byte]).decode('utf-8')
                        current.append(char)
                        continue
                    except:
                        pass
            current.append(' ')
        else:
            # Binary karakter - mevcut diziyi deÄŸerlendir
            if len(current) >= min_len:
                text = ''.join(current).strip()
                # Kalite kontrolÃ¼: Yeterli harf iÃ§eriyor mu?
                alpha_ratio = sum(c.isalpha() for c in text) / max(len(text), 1)
                if alpha_ratio > 0.5 and len(text) >= min_len and len(text) <= max_len:
                    # Kelime boÅŸluklarÄ± var mÄ±?
                    if text.count(' ') > 5:
                        texts.append(text)
            current = []
    
    return texts


def classify_texts(texts: list[str]) -> tuple[list[str], list[str]]:
    """
    Metinleri kullanÄ±cÄ± (Context) ve danÄ±ÅŸman (Response) olarak sÄ±nÄ±flar.
    
    Args:
        texts: TÃ¼m temiz metinler
    
    Returns:
        (contexts, responses) tuple'Ä±
    """
    # KullanÄ±cÄ± mesajÄ± kalÄ±plarÄ±
    user_patterns = [
        r"^I[\'']m\s", r"^I\s", r"^My\s", r"^We\s",
        r"\?$", r"I feel", r"I have been", r"I don\'t know",
        r"struggling|going through|having trouble|worried|concerned|stressed|anxious|depressed"
    ]
    
    # DanÄ±ÅŸman mesajÄ± kalÄ±plarÄ±
    counselor_patterns = [
        r"^It sounds like", r"^Thank you for", r"^I hear", r"^That sounds",
        r"therapist|counselor|therapy|treatment",
        r"suggest|recommend|encourage|consider",
        r"practice|skill|technique|explore",
        r"^What you", r"^Have you", r"^You might"
    ]
    
    contexts = []
    responses = []
    
    for text in texts:
        is_user = any(re.search(pat, text, re.IGNORECASE) for pat in user_patterns)
        is_counselor = any(re.search(pat, text, re.IGNORECASE) for pat in counselor_patterns)
        
        # Sondaki Ã§Ã¶p karakterleri temizle
        text = re.sub(r'[^\x20-\x7e\n\r]+$', '', text)
        
        if is_counselor and len(text) > 100:
            if text not in responses:
                responses.append(text)
        elif is_user and not is_counselor and len(text) > 50:
            if text not in contexts:
                contexts.append(text)
    
    return contexts, responses


# =============================================================================
# BÃ–LÃœM 2: CGI LENS (SOKRATIK LENS)
# =============================================================================

CGI_LENS = {
    "name": "Mental Health Counseling Lens",
    
    "decision_question": """
    Bu yanÄ±t kullanÄ±cÄ±nÄ±n TEMEL Ã‡ERÃ‡EVESÄ°NÄ° deÄŸiÅŸtiriyor mu
    (kendini, problemini, mÃ¼mkÃ¼n olanÄ± nasÄ±l gÃ¶rdÃ¼ÄŸÃ¼)
    yoksa sadece o Ã§erÃ§eve Ä°Ã‡Ä°NDE doÄŸruluyor/optimize mi ediyor?
    """,
    
    "transformative_signals": [
        ("Invites reframing", r"(what if|imagine|consider that|have you thought about|reframe|perspective)"),
        ("Challenges self-definition", r"(who you are|your identity|you are not|you are more than|rooted in|underlying)"),
        ("Points to underlying issue", r"(the real question|beneath|deeper|root|actually about)"),
        ("Reframes ontology", r"(isn\'t about|not really about|what it means to)"),
        ("Hypothetical reframe", r"(what would.*mean|if.*were true|suppose)")
    ],
    
    "mechanical_signals": [
        ("Validation/reflection", r"(it sounds like you|I hear that|I understand|that must be)"),
        ("Technique recommendation", r"(try|technique|skill|practice|exercise|breathing|meditation)"),
        ("Professional referral", r"(therapist|counselor|professional|doctor|seek help)"),
        ("Behavioral advice", r"(should|need to|have to|consider doing|suggest)"),
        ("Normalization", r"(normal|common|many people|not alone|others feel)")
    ]
}


def analyze_response(response: str) -> dict:
    """
    Bir danÄ±ÅŸman yanÄ±tÄ±nÄ± CGI lens ile analiz eder.
    
    Args:
        response: DanÄ±ÅŸman yanÄ±t metni
    
    Returns:
        Analiz sonucu dictionary
    """
    transformative = []
    mechanical = []
    
    # Transformatif sinyalleri kontrol et
    for name, pattern in CGI_LENS["transformative_signals"]:
        if re.search(pattern, response, re.IGNORECASE):
            transformative.append(name)
    
    # Mekanik sinyalleri kontrol et
    for name, pattern in CGI_LENS["mechanical_signals"]:
        if re.search(pattern, response, re.IGNORECASE):
            mechanical.append(name)
    
    # Karar ver
    t_score = len(transformative)
    m_score = len(mechanical)
    
    if t_score >= 2 and t_score > m_score:
        verdict = 'TRANSFORMATIVE'
        confidence = 'high' if t_score >= 3 else 'medium'
        reasoning = transformative
    elif m_score >= 1:
        verdict = 'MECHANICAL'
        confidence = 'high' if m_score >= 3 else ('medium' if m_score >= 2 else 'low')
        reasoning = mechanical
    else:
        verdict = 'MECHANICAL'
        confidence = 'low'
        reasoning = ["No clear frame transformation detected"]
    
    return {
        'verdict': verdict,
        'confidence': confidence,
        'reasoning': reasoning,
        'transformative_signals': transformative,
        'mechanical_signals': mechanical
    }


# =============================================================================
# BÃ–LÃœM 3: ANA ANALÄ°Z FONKSÄ°YONU
# =============================================================================

def run_cgi_analysis(filepath: str, sample_size: int = 20, seed: int = 42) -> dict:
    """
    CGI analizini Ã§alÄ±ÅŸtÄ±rÄ±r.
    
    Args:
        filepath: Parquet dosya yolu
        sample_size: Analiz edilecek Ã¶rnek sayÄ±sÄ±
        seed: Rastgelelik tohumu (tekrarlanabilirlik iÃ§in)
    
    Returns:
        Analiz sonuÃ§larÄ± dictionary
    """
    random.seed(seed)
    
    # Veriyi oku
    print("[1/4] Veri okunuyor...")
    with open(filepath, 'rb') as f:
        data = f.read()
    
    # Metinleri Ã§Ä±kar
    print("[2/4] Metinler Ã§Ä±karÄ±lÄ±yor...")
    texts = extract_clean_texts(data, min_len=80)
    print(f"      â†’ {len(texts)} temiz metin bloÄŸu bulundu")
    
    # SÄ±nÄ±flandÄ±r
    print("[3/4] Metinler sÄ±nÄ±flandÄ±rÄ±lÄ±yor...")
    contexts, responses = classify_texts(texts)
    print(f"      â†’ {len(contexts)} kullanÄ±cÄ± mesajÄ±")
    print(f"      â†’ {len(responses)} danÄ±ÅŸman yanÄ±tÄ±")
    
    # Ã–rnekle ve analiz et
    print(f"[4/4] {sample_size} Ã¶rnek analiz ediliyor...")
    sample = random.sample(responses, min(sample_size, len(responses)))
    
    results = []
    for idx, response in enumerate(sample, 1):
        analysis = analyze_response(response)
        results.append({
            'id': idx,
            'text': response,
            **analysis
        })
    
    # Ä°statistikler
    stats = {
        'total_texts': len(texts),
        'contexts': len(contexts),
        'responses': len(responses),
        'sample_size': len(sample),
        'transformative': sum(1 for r in results if r['verdict'] == 'TRANSFORMATIVE'),
        'mechanical': sum(1 for r in results if r['verdict'] == 'MECHANICAL')
    }
    
    return {
        'results': results,
        'stats': stats,
        'lens': CGI_LENS
    }


# =============================================================================
# BÃ–LÃœM 4: RAPOR ÃœRETÄ°CÄ°
# =============================================================================

def generate_report(analysis: dict) -> str:
    """
    Markdown formatÄ±nda rapor Ã¼retir.
    """
    lines = []
    stats = analysis['stats']
    results = analysis['results']
    
    lines.append("# CGI Analysis Report: Mental Health Counseling Dataset")
    lines.append("## Context Grammar Induction (Socratic Lens) Analysis")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # Lens bilgisi
    lines.append("## Lens Configuration")
    lines.append("")
    lines.append("**Decision Question:** Does the counselor's response shift the user's underlying frame (Ontology/Belief) or just validate/optimize it?")
    lines.append("")
    lines.append("**Transformative Signals:**")
    for name, _ in CGI_LENS["transformative_signals"]:
        lines.append(f"- {name}")
    lines.append("")
    lines.append("**Mechanical Signals:**")
    for name, _ in CGI_LENS["mechanical_signals"]:
        lines.append(f"- {name}")
    lines.append("")
    
    # Ã–zet
    lines.append("---")
    lines.append("")
    lines.append("## Summary")
    lines.append("")
    lines.append(f"| Metric | Value |")
    lines.append(f"|--------|-------|")
    lines.append(f"| Total texts extracted | {stats['total_texts']} |")
    lines.append(f"| User contexts | {stats['contexts']} |")
    lines.append(f"| Counselor responses | {stats['responses']} |")
    lines.append(f"| Samples analyzed | {stats['sample_size']} |")
    lines.append(f"| **TRANSFORMATIVE** | {stats['transformative']} |")
    lines.append(f"| **MECHANICAL** | {stats['mechanical']} |")
    lines.append("")
    
    # DetaylÄ± tablo
    lines.append("---")
    lines.append("")
    lines.append("## Detailed Results")
    lines.append("")
    lines.append("| # | Verdict | Confidence | Key Signals | Response Preview |")
    lines.append("|---|---------|------------|-------------|------------------|")
    
    for r in results:
        preview = r['text'][:80].replace('\n', ' ').replace('|', '/') + "..."
        signals = ', '.join(r['reasoning'][:2]) if r['reasoning'] else "N/A"
        lines.append(f"| {r['id']:02d} | **{r['verdict']}** | {r['confidence']} | {signals} | {preview} |")
    
    lines.append("")
    
    # Transformatif Ã¶rnekler
    transformative = [r for r in results if r['verdict'] == 'TRANSFORMATIVE']
    if transformative:
        lines.append("---")
        lines.append("")
        lines.append("## ðŸ”¥ TRANSFORMATIVE EXAMPLES")
        lines.append("")
        for r in transformative:
            lines.append(f"### Sample #{r['id']}")
            lines.append(f"**Confidence:** {r['confidence']}")
            lines.append("")
            lines.append("**Signals:**")
            for sig in r['transformative_signals']:
                lines.append(f"- {sig}")
            lines.append("")
            lines.append("**Text:**")
            lines.append(f"> {r['text'][:500]}...")
            lines.append("")
    else:
        lines.append("---")
        lines.append("")
        lines.append("## Result: No Context Shifts Found")
        lines.append("")
        lines.append("All analyzed responses operate **MECHANICALLY**.")
        lines.append("")
    
    # Sokratik yansÄ±ma
    lines.append("---")
    lines.append("")
    lines.append("## Socratic Meta-Reflection")
    lines.append("")
    lines.append("Mental health counseling responses in this dataset predominantly operate in **MECHANICAL mode** - they help users cope within their existing frame rather than transforming that frame.")
    lines.append("")
    lines.append("**[HUMAN DECISION NEEDED]**")
    lines.append("Whether a mechanical response is 'right' depends on context. The system can **SHOW** this distinction; it cannot **DECIDE** which is appropriate.")
    
    return '\n'.join(lines)


# =============================================================================
# BÃ–LÃœM 5: ANA GÄ°RÄ°Åž NOKTASI
# =============================================================================

def main():
    """Ana fonksiyon."""
    # Dosya yolu
    if len(sys.argv) > 1:
        filepath = sys.argv[1]
    else:
        filepath = "/mnt/user-data/uploads/0000.parquet"
    
    if not Path(filepath).exists():
        print(f"Hata: Dosya bulunamadÄ±: {filepath}")
        sys.exit(1)
    
    print("="*60)
    print("CGI ANALYSIS: MENTAL HEALTH COUNSELING DATASET")
    print("="*60)
    print()
    
    # Analiz Ã§alÄ±ÅŸtÄ±r
    analysis = run_cgi_analysis(filepath, sample_size=20)
    
    print()
    print("="*60)
    print("RESULTS")
    print("="*60)
    print(f"TRANSFORMATIVE: {analysis['stats']['transformative']}")
    print(f"MECHANICAL: {analysis['stats']['mechanical']}")
    print()
    
    # DetaylarÄ± gÃ¶ster
    for r in analysis['results']:
        print(f"[{r['id']:02d}] [{r['verdict']}] ({r['confidence']})")
        print(f"     {r['reasoning']}")
        print(f"     {r['text'][:100]}...")
        print()
    
    # Rapor Ã¼ret
    report = generate_report(analysis)
    
    output_path = "cgi_report.md"
    with open(output_path, 'w') as f:
        f.write(report)
    
    print(f"Rapor kaydedildi: {output_path}")


if __name__ == "__main__":
    main()
